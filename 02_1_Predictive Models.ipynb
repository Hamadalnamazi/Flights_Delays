{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, pickle\n",
    "import datetime as dt\n",
    "\n",
    "# initialize a connection to the database\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('../Spotify_Challenge/dbsql.db')\n",
    "\n",
    "# initialize another sqlalchemy connection to the same database to be able to query data straight to pandas dataframe\n",
    "from sqlalchemy import create_engine\n",
    "disk_engine = create_engine('sqlite:///../Spotify_Challenge/dbsql.db')\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use data collected from [transtats.bts.gov](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) to a local database and directly from [faa.gov](http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/previous_years/). We will be making queries to the database using sqlite commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_to_week(year,month,day):\n",
    "    \"\"\"return week of the year\"\"\"\n",
    "    return dt.date(year,month,day).isocalendar()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get 2014 airports ranking from FAA\n",
    "links = [[2015,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/preliminary-cy15-commercial-service-enplanements.xlsx\"],\n",
    "         [2014,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/cy14-commercial-service-enplanements.xlsx\"],\n",
    "         [2013,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/cy13-commercial-service-enplanements.xlsx\"],\n",
    "         [2012,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/CY12CommercialServiceEnplanements.xlsx\"],\n",
    "         [2011,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/cy11_primary_enplanements.xlsx\"],\n",
    "         [2010,\"http://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/cy10_primary_enplanements.xls\"]]\n",
    "ranks = pd.DataFrame()\n",
    "for link in sorted(links):\n",
    "    df = pd.read_excel(link[1])\n",
    "    df.rename(columns={df.columns[-2]:\"Enplanement\",df.columns[-1]:\"Change\"}, inplace=True)\n",
    "    df['Year'] = link[0]\n",
    "    ranks = pd.concat([ranks,df[['Year','Rank','Locid','Hub','Enplanement','Change']]],axis=0,ignore_index=True)\n",
    "    \n",
    "# only focus on airports classified as large hubs\n",
    "ranks = ranks[ranks.Hub == \"L\"]\n",
    "# drop rows which do not correspond to airports data and reset indices\n",
    "indices_to_drop = ranks[ranks.Locid.isnull()].index.tolist()\n",
    "ranks.drop(indices_to_drop,inplace=True)\n",
    "ranks = ranks.reset_index()\n",
    "large_hubs = map(lambda x:str(x),pd.unique(ranks[ranks.Hub == \"L\"][\"Locid\"]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get aggreagated airports data from the database\n",
    "airports = pd.read_sql_query(\"select * from airports_clusters\",disk_engine)\n",
    "# Focus on large hubs only\n",
    "airports = airports[airports.IATA.isin(large_hubs)].reset_index()[['YEAR','IATA','C1','C2']]\n",
    "# merge airports with their ranking\n",
    "airports = pd.merge(airports,ranks[[u'Year', u'Rank', u'Locid', u'Enplanement',u'Change']],\n",
    "                    how='left',left_on=['YEAR','IATA'],right_on=['Year','Locid'])\n",
    "airports.drop(['Year','Locid'],axis=1,inplace=True)\n",
    "airports.columns = map(lambda x:str(x).upper(),airports.columns.tolist())\n",
    "# get aggregated flights data from the database\n",
    "flights = pd.read_sql_query(\"select * from flights_clusters\",disk_engine)[['YEAR','ORIGIN','DEST','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [u'index',u'YEAR', u'QUARTER', u'MONTH', u'DAY_OF_MONTH', u'DAY_OF_WEEK', u'AIRLINE_ID', \n",
    "            u'CARRIER', u'TAIL_NUM', u'FL_NUM', u'ORIGIN_AIRPORT_ID', u'ORIGIN', u'ORIGIN_CITY_NAME', \n",
    "            u'ORIGIN_STATE_NM', u'DEST_AIRPORT_ID', u'DEST', u'DEST_CITY_NAME', u'DEST_STATE_NM', \n",
    "            u'DEP_DELAY', u'DEP_DELAY_NEW', u'DEP_DEL15', u'TAXI_OUT', u'TAXI_IN', u'ARR_DELAY', \n",
    "            u'ARR_DELAY_NEW', u'ARR_DEL15', u'CANCELLED', u'CANCELLATION_CODE', u'DIVERTED', u'AIR_TIME', \n",
    "            u'FLIGHTS', u'DISTANCE', u'CARRIER_DELAY', u'WEATHER_DELAY', u'NAS_DELAY', u'SECURITY_DELAY', \n",
    "            u'LATE_AIRCRAFT_DELAY',u'FL_DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define **major airlines** as those airlines that were operational since 2010 until the end of year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:02.476330\n"
     ]
    }
   ],
   "source": [
    "tic = dt.datetime.now()\n",
    "airlines = pd.read_sql_query(\n",
    "    \"SELECT YEAR, CARRIER, COUNT(CARRIER) AS CARRIER_CNT \"\n",
    "    \"FROM data \"\n",
    "    \"WHERE YEAR <= 2015 \"\n",
    "    \"GROUP BY YEAR, CARRIER\",\n",
    "    disk_engine\n",
    ")\n",
    "# transform long table to wide\n",
    "airlines = pd.pivot(airlines.CARRIER,airlines.YEAR,airlines.CARRIER_CNT)\n",
    "\n",
    "# since we are only interested in airlines that were operational since 2010 until today,\n",
    "# let's drop all NaN and set columns titles as airlines (of interest)\n",
    "major_airlines = map(lambda x:str(x),airlines.dropna().index.tolist())\n",
    "print dt.datetime.now()-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000125\n"
     ]
    }
   ],
   "source": [
    "# get flights detailed data from the data base\n",
    "# we are going to only import those features which are known before the flight day: date, origin, destination and airline\n",
    "\n",
    "tic  =dt.datetime.now()\n",
    "if False:\n",
    "    data = pd.read_sql_query(\"SELECT YEAR, MONTH, DAY_OF_MONTH, DAY_OF_WEEK, ORIGIN, DEST, CARRIER, \"\n",
    "                             \"DEP_DEL15 AS DEP_DEL, DEP_DELAY AS DDEL1, DEP_DELAY_NEW AS DDEL2 \"\n",
    "                             \"FROM data \"\n",
    "                             \"WHERE ORIGIN IN {0} AND DEST IN {0} AND CARRIER IN {1}\".format(tuple(large_hubs),\n",
    "                                                                                             tuple(major_airlines)),\n",
    "                             disk_engine)\n",
    "print dt.datetime.now()-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:40.316076\n"
     ]
    }
   ],
   "source": [
    "tic = dt.datetime.now()\n",
    "# merge data with airports:\n",
    "## on origin airport\n",
    "new_data = pd.merge(data,airports, how='left',left_on=['YEAR','ORIGIN'],right_on=['YEAR','IATA'])\n",
    "new_data.drop('IATA',axis=1,inplace=True)\n",
    "## on destination airport\n",
    "new_data = pd.merge(new_data,airports, how='left',left_on=['YEAR','DEST'],right_on=['YEAR','IATA'])\n",
    "new_data.drop(['IATA'],axis=1,inplace=True)\n",
    "\n",
    "# merge data with flights\n",
    "new_data = pd.merge(new_data,flights,how='left', left_on=['YEAR','ORIGIN','DEST'], \n",
    "                    right_on=['YEAR','ORIGIN','DEST'])\n",
    "new_data.columns = ['YEAR','MONTH','DAY_OF_MONTH','DAY_OF_WEEK','ORIGIN','DEST','CARRIER','DEP_DEL','DDEL1','DDEL2',\n",
    "                    'C1_ORIG','C2_ORIG','RANK_ORIG','ENP_ORIG','CHA_ORIG',\n",
    "                    'C1_DEST','C2_DEST','RANK_DEST','ENP_DEST','CHA_DEST','C_FLIGHT']\n",
    "print dt.datetime.now()-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
